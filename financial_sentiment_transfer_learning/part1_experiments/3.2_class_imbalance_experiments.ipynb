{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Imbalance Experiments\n",
    "\n",
    "This notebook explores strategies to mitigate the effects of class imbalance in the Financial PhraseBank classification task. As demonstrated in the exploratory data analysis and the benchmark baseline (Section 3.1), the dataset is skewed toward Neutral sentiment, both in overall counts and particularly among short-length inputs. This imbalance leads to uneven model performance, with significantly lower recall for the Negative class.\n",
    "\n",
    "The goal of this notebook is to evaluate whether adjusting for class imbalance can improve macro-averaged performance and minority-class recall, without degrading overall accuracy. Ideally, the adjustments will lead to a fine-tuned classifier head with better perfomance. \n",
    "\n",
    "## Experiment Plan\n",
    "\n",
    "1. **Baseline Reproduction (Section 3.1 Reference)**  \n",
    "   Load and replicate the benchmark model with no class weighting to serve as a direct comparison.\n",
    "\n",
    "2. **Static Class Weights**  \n",
    "   Apply inverse-frequency class weights during training to emphasize minority classes.\n",
    "\n",
    "3. **Length-Aware Class Reweighting**  \n",
    "   Explore dynamic class weights or sampling techniques based on token length bins (e.g., over-weight short Negative examples).\n",
    "\n",
    "4. **Short Sequence Filtering**  \n",
    "   Evaluate the effect of removing or down-weighting very short, Neutral-dominant sequences.\n",
    "\n",
    "5. **Combined Strategy**  \n",
    "   Combine class weighting with input filtering to assess cumulative gains.\n",
    "\n",
    "6. **Performance Comparison and Summary**  \n",
    "   Compare all approaches to the benchmark using macro F1, per-class recall, and confusion matrices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Up to 3.1 Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets scikit-learn pandas numpy tqdm tensorflow\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "from datasets import load_dataset # Hugging Face\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "# Compute class weights per bin\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the \"all agree\" subset\n",
    "dataset = load_dataset(\"financial_phrasebank\", \"sentences_allagree\") # All agree signifies 100% of annotators agreed on sentiment of this subset\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "# Tokenization\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256  # Based on EDA to cover 100% of samples\n",
    "    )\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Train-test-validation split (80/10/10 stratified)\n",
    "train_val_split = tokenized_datasets[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "val_test_split = train_val_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "# Convert to TensorFlow datasets\n",
    "def to_tf_dataset(split, shuffle=False):\n",
    "    return split.to_tf_dataset(\n",
    "        columns=[\"input_ids\", \"attention_mask\"],\n",
    "        label_cols=[\"label\"],\n",
    "        shuffle=shuffle,\n",
    "        batch_size=16,\n",
    "        collate_fn=None\n",
    "    )\n",
    "\n",
    "tf_train_dataset = to_tf_dataset(train_val_split[\"train\"], shuffle=True)\n",
    "tf_validation_dataset = to_tf_dataset(val_test_split[\"train\"], shuffle=True)\n",
    "tf_test_dataset = to_tf_dataset(val_test_split[\"test\"], shuffle=False)\n",
    "\n",
    "# Load model\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=3\n",
    ")\n",
    "\n",
    "# Freeze encoder\n",
    "model.distilbert.trainable = False  # frozen encoder\n",
    "\n",
    "# Compile model\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_validation_dataset,\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Static Class Weighting\n",
    "\n",
    "This experiment applies inverse-frequency class weights during training to penalize errors on underrepresented classes. The class weights are computed based on the training split label distribution. This provides a simple and interpretable baseline for imbalance-aware training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Compute class weights from training set labels\n",
    "train_labels = [example['label'] for example in train_val_split['train']]\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"Class Weights:\", class_weight_dict)\n",
    "\n",
    "# Recompile the model with class weights\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n",
    "model.distilbert.trainable = False\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Wrap with weighted loss\n",
    "def weighted_loss(y_true, y_pred):\n",
    "    weights = tf.gather(\n",
    "        tf.constant([class_weight_dict[i] for i in range(3)], dtype=tf.float32),\n",
    "        tf.cast(y_true, tf.int32)\n",
    "    )\n",
    "    unweighted_loss = loss_fn(y_true, y_pred)\n",
    "    return tf.reduce_mean(unweighted_loss * weights)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=weighted_loss, metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dynamic Class Weighting Based on Token Length\n",
    "\n",
    "This experiment explores a more granular weighting scheme that accounts not only for class imbalance but also for how that imbalance varies across sentence lengths.\n",
    "\n",
    "A quantile-based binning strategy is used to split the training data into length-based bins. Within each bin, class proportions are computed and used to generate local class weights. These weights are then dynamically applied during training based on the token length of each input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Bin training set into short/mid/long based on quantiles\n",
    "lengths = [len(tokenizer.tokenize(ex['sentence'])) for ex in train_val_split['train']]\n",
    "q1, q2 = np.percentile(lengths, [33, 66])\n",
    "\n",
    "def assign_length_bin(length):\n",
    "    if length <= q1:\n",
    "        return 'short'\n",
    "    elif length <= q2:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'long'\n",
    "\n",
    "# Attach bin labels\n",
    "for ex in train_val_split['train']:\n",
    "    ex['length_bin'] = assign_length_bin(len(tokenizer.tokenize(ex['sentence'])))\n",
    "\n",
    "\n",
    "\n",
    "bin_class_counts = defaultdict(Counter)\n",
    "for ex in train_val_split['train']:\n",
    "    bin_class_counts[ex['length_bin']][ex['label']] += 1\n",
    "\n",
    "# Convert to weights (inverse frequency)\n",
    "dynamic_class_weights = {}\n",
    "for bin_name, counts in bin_class_counts.items():\n",
    "    total = sum(counts.values())\n",
    "    weights = {cls: total / (len(counts) * count) for cls, count in counts.items()}\n",
    "    dynamic_class_weights[bin_name] = weights\n",
    "\n",
    "print(dynamic_class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
