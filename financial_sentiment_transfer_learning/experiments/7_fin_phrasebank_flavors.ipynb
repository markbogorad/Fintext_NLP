{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "test_datasets_accuracy = []\n",
    "dataset_flavours = [\"sentences_allagree\", \"sentences_75agree\", \"sentences_66agree\", \"sentences_50agree\"]\n",
    "\n",
    "for i, dataset_flavour in enumerate(dataset_flavours):\n",
    "    print(\"Running for financial_phrasebank :\", dataset_flavour)\n",
    "\n",
    "    # Load dataset and tokenizer\n",
    "    dataset = load_dataset(\"financial_phrasebank\", dataset_flavour)\n",
    "    checkpoint = \"distilbert-base-uncased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"sentence\"],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        )\n",
    "\n",
    "    tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    train_val_split = tokenized_datasets[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "    val_test_split = train_val_split['test'].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "    def to_tf_dataset(split, shuffle=False):\n",
    "        return split.to_tf_dataset(\n",
    "            columns=[\"input_ids\", \"attention_mask\"],\n",
    "            label_cols=[\"label\"],\n",
    "            shuffle=shuffle,\n",
    "            batch_size=8,\n",
    "            collate_fn=None\n",
    "        )\n",
    "\n",
    "    tf_train_dataset = to_tf_dataset(train_val_split['train'], shuffle=True)\n",
    "    tf_validation_dataset = to_tf_dataset(val_test_split['train'], shuffle=True)\n",
    "    tf_test_dataset = to_tf_dataset(val_test_split['test'], shuffle=False)\n",
    "\n",
    "    # Define and compile model\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n",
    "    model.distilbert.trainable = False\n",
    "\n",
    "    initial_learning_rate = 5e-5\n",
    "    lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "        initial_learning_rate=initial_learning_rate,\n",
    "        decay_steps=10000,\n",
    "        end_learning_rate=0.0,\n",
    "        power=1.0\n",
    "    )\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # Training\n",
    "    model.fit(tf_train_dataset, epochs=3, validation_data=tf_validation_dataset)\n",
    "\n",
    "    # Evaluation\n",
    "    eval_loss, eval_accuracy = model.evaluate(tf_test_dataset)\n",
    "    print(f\"For {dataset_flavour}, Evaluated Test Loss: {eval_loss}, Evaluated Test Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    # Prediction and Manual Calculation of Metrics\n",
    "    input_ids, y_true, y_pred_logits = [], [], []\n",
    "    for batch in tf_test_dataset:\n",
    "        ids = batch[0]['input_ids'].numpy()\n",
    "        labels = batch[1].numpy()\n",
    "        input_ids.extend(ids)\n",
    "        y_true.extend(labels)\n",
    "        logits = model.predict(batch[0], verbose=0)\n",
    "        y_pred_logits.extend(logits.logits)\n",
    "\n",
    "    predicted_class = np.argmax(y_pred_logits, axis=1)\n",
    "\n",
    "    # Calculate and print manual accuracy\n",
    "    manual_accuracy = np.mean(np.array(y_true) == predicted_class)\n",
    "    print(f\"Manually Calculated Test Accuracy: {manual_accuracy}\")\n",
    "\n",
    "    # Additional reporting\n",
    "    report = classification_report(y_true, predicted_class, target_names=['Negative', 'Neutral', 'Positive'])\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    cm = confusion_matrix(y_true, predicted_class)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    test_datasets_accuracy.append({\n",
    "        \"run\": i,\n",
    "        \"flavour\": dataset_flavour,\n",
    "        \"loss\": eval_loss,\n",
    "        \"accuracy\": eval_accuracy\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to store the dataset flavours, accuracies, and losses\n",
    "flavours = []\n",
    "accuracies = []\n",
    "losses = []\n",
    "\n",
    "# Extract data from the test_datasets_accuracy list of dictionaries\n",
    "for entry in test_datasets_accuracy:\n",
    "    flavours.append(entry[\"flavour\"])\n",
    "    accuracies.append(entry[\"accuracy\"]*100)\n",
    "    losses.append(entry[\"loss\"])\n",
    "\n",
    "# Plotting accuracy vs. dataset flavour\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(flavours, accuracies, marker='o', linestyle='-', color='b', label='Accuracy (%)')\n",
    "plt.title('Model Accuracy vs. Dataset Flavour')\n",
    "plt.xlabel('# Training Examples')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plotting loss vs. dataset flavour\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(flavours, losses, marker='o', linestyle='-', color='r', label='Loss')\n",
    "plt.title('Model Loss vs. Dataset Flavour')\n",
    "plt.xlabel('# Training Examples')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
