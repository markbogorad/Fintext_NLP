{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset and tokenizer\n",
    "dataset = load_dataset(\"financial_phrasebank\", \"sentences_allagree\")\n",
    "checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_val_split = tokenized_datasets[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "val_test_split = train_val_split['test'].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "def to_tf_dataset(split, shuffle=False):\n",
    "    return split.to_tf_dataset(\n",
    "        columns=[\"input_ids\", \"attention_mask\"],\n",
    "        label_cols=[\"label\"],\n",
    "        shuffle=shuffle,\n",
    "        batch_size=8,\n",
    "        collate_fn=None\n",
    "    )\n",
    "\n",
    "tf_train_dataset = to_tf_dataset(train_val_split['train'], shuffle=True)\n",
    "tf_validation_dataset = to_tf_dataset(val_test_split['train'], shuffle=True)\n",
    "tf_test_dataset = to_tf_dataset(val_test_split['test'], shuffle=False)\n",
    "\n",
    "# Define and compile model\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n",
    "model.bert.trainable = False\n",
    "\n",
    "initial_learning_rate = 5e-5\n",
    "lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    end_learning_rate=0.0,\n",
    "    power=1.0\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Training\n",
    "model.fit(tf_train_dataset, epochs=3, validation_data=tf_validation_dataset)\n",
    "\n",
    "# Evaluation\n",
    "eval_loss, eval_accuracy = model.evaluate(tf_test_dataset)\n",
    "print(f\"Evaluated Test Loss: {eval_loss}, Evaluated Test Accuracy: {eval_accuracy}\")\n",
    "\n",
    "# Prediction and Manual Calculation of Metrics\n",
    "input_ids, y_true, y_pred_logits = [], [], []\n",
    "for batch in tf_test_dataset:\n",
    "    ids = batch[0]['input_ids'].numpy()\n",
    "    labels = batch[1].numpy()\n",
    "    input_ids.extend(ids)\n",
    "    y_true.extend(labels)\n",
    "    logits = model.predict(batch[0], verbose=0)\n",
    "    y_pred_logits.extend(logits.logits)\n",
    "\n",
    "predicted_class = np.argmax(y_pred_logits, axis=1)\n",
    "\n",
    "# Calculate and print manual accuracy\n",
    "manual_accuracy = np.mean(np.array(y_true) == predicted_class)\n",
    "print(f\"Manually Calculated Test Accuracy: {manual_accuracy}\")\n",
    "\n",
    "# Additional reporting\n",
    "report = classification_report(y_true, predicted_class, target_names=['Negative', 'Neutral', 'Positive'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "cm = confusion_matrix(y_true, predicted_class)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
